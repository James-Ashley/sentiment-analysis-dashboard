{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "80-20_tf-idf_all_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUVgL1wNNajZ",
        "outputId": "83a057dd-fa02-4206-b7fe-c953c45dc8a3"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-2.4.6'\n",
        "spark_version = 'spark-2.4.7'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oti61dTfUHx"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"PerceptronModels\").config('spark.executor.memory', '8G').config('spark.driver.memory', '8G').config('spark.driver.maxResultSize', '8G').config(\"spark.memory.offHeap.size\",\"8g\").config(\"spark.memory.offHeap.enabled\",True).getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3nlquuj2kDf"
      },
      "source": [
        "# Read in data from Github\r\n",
        "from pyspark import SparkFiles\r\n",
        "url =\"https://raw.githubusercontent.com/James-Ashley/sentiment-analysis-dashboard/main/sentiment_classification/preprocessed_headlines.json\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df_git = spark.read.json(SparkFiles.get(\"preprocessed_headlines.json\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FahATHDs3iJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533124f9-09e8-4ff3-c3cc-097ffcfc8aef"
      },
      "source": [
        "df_git.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------+-----------+--------------+-------------+--------------+--------------------+---------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              author|   cleaned_headlines|compound_score|    keyword|negative_score|neutral_score|positive_score|           published|sentiment_human|  source|       text_complete|        text_excerpt|               tfidf|               title|              tokens|         tokens_lems|                 url|\n",
            "+--------------------+--------------------+--------------+-----------+--------------+-------------+--------------+--------------------+---------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|           Dip Patel|could deport pare...|        0.1027|immigration|           0.0|        0.896|         0.104|2020-12-04T09:32:20Z|             -1|NBC News|As an inpatient h...|As an inpatient h...|[0.0, 0.0, 0.0, 0...|I could be deport...|[i, could, be, de...|[could, deport, p...|https://www.nbcne...|\n",
            "|      Suzanne Gamboa|first latino tapp...|           0.0|immigration|           0.0|          1.0|           0.0|2020-11-23T22:41:00Z|              0|NBC News|Alejandro Mayorka...|Alejandro Mayorka...|[0.0, 0.0, 0.0, 0...|First Latino tapp...|[first, latino, t...|[first, latino, t...|https://www.nbcne...|\n",
            "|       Cynthia Silva|tony pham interim...|           0.0|immigration|           0.0|          1.0|           0.0|2020-12-14T22:28:21Z|              0|NBC News|Tony Pham will be...|Tony Pham will be...|[0.0, 0.0, 0.0, 0...|Tony Pham, interi...|[tony, pham, inte...|[tony, pham, inte...|https://www.nbcne...|\n",
            "|Julia Ainsley and...|two third undocum...|       -0.3818|immigration|         0.157|        0.843|           0.0|2020-12-16T22:46:58Z|              0|NBC News|WASHINGTON — More...|WASHINGTON More t...|[0.0, 0.0, 0.0, 0...|More than two-thi...|[more, than, two,...|[two, third, undo...|https://www.nbcne...|\n",
            "|Rebecca Shabad, A...|biden meet strugg...|       -0.7845|immigration|         0.365|        0.635|           0.0|2020-12-02T21:56:00Z|             -1|NBC News|President-elect J...|President-elect J...|[0.0, 0.0, 0.0, 0...|Biden to meet wit...|[biden, to, meet,...|[biden, meet, str...|https://www.nbcne...|\n",
            "|April Glaser and ...|accuse hate group...|       -0.7096|immigration|         0.596|        0.404|           0.0|2020-12-09T15:45:39Z|             -1|NBC News|Fourteen organiza...|Fourteen organiza...|[0.0, 0.0, 0.0, 0...|Accused hate grou...|[accused, hate, g...|[accuse, hate, gr...|https://www.nbcne...|\n",
            "|Julia Ainsley and...|lawyer say trump ...|        0.4019|immigration|           0.0|        0.838|         0.162|2020-12-03T01:41:59Z|              1|NBC News|WASHINGTON — Lega...|WASHINGTON Legal ...|[0.0, 0.0, 0.0, 0...|Lawyers say Trump...|[lawyers, say, tr...|[lawyer, say, tru...|https://www.nbcne...|\n",
            "|       Julia Ainsley|28 migrant child ...|       -0.4019|immigration|         0.184|        0.816|           0.0|2020-11-23T20:22:00Z|             -1|NBC News|WASHINGTON — Twen...|WASHINGTON Twenty...|[0.0, 0.0, 0.0, 0...|28 migrant childr...|[28, migrant, chi...|[28, migrant, chi...|https://www.nbcne...|\n",
            "|    Julianne McShane|visa delay leave ...|       -0.0516|immigration|         0.107|        0.893|           0.0|2020-12-18T23:52:38Z|             -1|NBC News|When Shilpa Sachd...|When Shilpa Sachd...|[0.0, 0.0, 0.0, 0...|Visa delays leave...|[visa, delays, le...|[visa, delay, lea...|https://www.nbcne...|\n",
            "|Julia Ainsley and...|advocate mental h...|           0.0|immigration|         0.126|        0.747|         0.126|2020-12-09T19:14:50Z|              0|NBC News|WASHINGTON — Immi...|WASHINGTON Immigr...|[0.0, 0.0, 0.0, 0...|Advocates, mental...|[advocates, menta...|[advocate, mental...|https://www.nbcne...|\n",
            "|       Adela Suliman|u k first non whi...|        0.6705|immigration|         0.173|        0.422|         0.405|2020-11-25T12:01:00Z|              1|NBC News|LONDON — It's bee...|LONDON It's been ...|[0.0, 0.0, 0.0, 0...|U.K.'s first non-...|[u, k, s, first, ...|[u, k, first, non...|https://www.nbcne...|\n",
            "|       Raul A. Reyes|12 great latino b...|        0.6249|immigration|           0.0|        0.549|         0.451|2020-12-17T15:49:31Z|              1|NBC News|Our editors indep...|In a year defined...|[0.0, 0.0, 0.0, 0...|12 great Latino b...|[12, great, latin...|[12, great, latin...|https://www.nbcne...|\n",
            "|         Sahil Kapur|feinstein say ste...|        0.2023|immigration|           0.0|        0.859|         0.141|2020-11-23T23:46:20Z|              0|NBC News|WASHINGTON — Sen....|WASHINGTON Sen. D...|[0.0, 0.0, 0.0, 0...|Feinstein says sh...|[feinstein, says,...|[feinstein, say, ...|https://www.nbcne...|\n",
            "|The Associated Press|judge throw trump...|           0.0|immigration|           0.0|          1.0|           0.0|2020-12-02T01:05:00Z|              0|NBC News|CHICAGO — A feder...|CHICAGO A federal...|[0.0, 0.0, 0.0, 0...|Judge throws out ...|[judge, throws, o...|[judge, throw, tr...|https://www.nbcne...|\n",
            "|         Tim Stelloh|san francisco off...|       -0.6808|immigration|         0.569|        0.431|           0.0|2020-12-07T23:59:04Z|             -1|NBC News|A San Francisco g...|A San Francisco g...|[0.0, 0.0, 0.0, 0...|San Francisco off...|[san, francisco, ...|[san, francisco, ...|https://www.nbcne...|\n",
            "|     Alberto Halpern|latino catholic c...|           0.0|immigration|           0.0|          1.0|           0.0|2020-12-11T21:47:31Z|              0|NBC News|EL PASO, Texas — ...|EL PASO, TexasThe...|[0.0, 0.0, 0.0, 0...|Latino Catholics ...|[latino, catholic...|[latino, catholic...|https://www.nbcne...|\n",
            "|       Raul A. Reyes|covid 19 regulati...|        0.5574|immigration|           0.0|        0.753|         0.247|2020-11-27T12:30:48Z|             -1|NBC News|In a Supreme Cour...|In a Supreme Cour...|[0.0, 0.0, 0.0, 0...|In Covid-19 regul...|[in, covid, 19, r...|[covid, 19, regul...|https://www.nbcne...|\n",
            "|       NBC Universal|pope installs new...|           0.0|immigration|           0.0|          1.0|           0.0|2020-11-28T17:26:00Z|              0|NBC News|VATICAN CITY (Reu...|VATICAN CITY (Reu...|[0.0, 0.0, 0.0, 0...|Pope installs new...|[pope, installs, ...|[pope, installs, ...|https://www.nbcne...|\n",
            "|      Daniella Silva|trump immigration...|           0.0|immigration|           0.0|          1.0|           0.0|2020-11-25T10:01:18Z|              0|NBC News|When President Do...|When President Do...|[0.0, 0.0, 0.0, 0...|Why Trump's immig...|[why, trump, s, i...|[trump, immigrati...|https://www.nbcne...|\n",
            "|      Nicole Acevedo|trump administrat...|       -0.5574|immigration|         0.338|        0.662|           0.0|2020-11-24T23:18:15Z|              1|NBC News|Two U.S. women wh...|Two U.S. women wh...|[0.0, 0.0, 0.0, 0...|Trump administrat...|[trump, administr...|[trump, administr...|https://www.nbcne...|\n",
            "+--------------------+--------------------+--------------+-----------+--------------+-------------+--------------+--------------------+---------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUGl4Ris4OoS"
      },
      "source": [
        "df_git_clean = df_git.select('sentiment_human', 'tokens_lems').withColumnRenamed('sentiment_human', 'label')\r\n",
        "\r\n",
        "#df_git_clean.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_m68xsHC0ny"
      },
      "source": [
        "from pyspark.sql.functions import when\r\n",
        "\r\n",
        "df_git_clean = df_git_clean.withColumn(\"label\", \\\r\n",
        "              when(df_git_clean[\"label\"] == -1, 2).otherwise(df_git_clean[\"label\"]))\r\n",
        "\r\n",
        "#df_git_clean.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sis5N9tCt-D4"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer\r\n",
        "# Create all the features for the data set\r\n",
        "\r\n",
        "# hashing\r\n",
        "hashingTF = HashingTF(numFeatures=2**13, inputCol=\"tokens_lems\", outputCol='hash_token')\r\n",
        "# idf\r\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-6iP3be7Wgt"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "from pyspark.ml.linalg import Vector\r\n",
        "\r\n",
        "# Create feature vectors - this assemble all columns you want to use as features\r\n",
        "clean_up = VectorAssembler(inputCols=['idf_token'], outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMoqu6KS7WpK"
      },
      "source": [
        "# Create and run a data processing Pipeline\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "data_prep_pipeline = Pipeline(stages=[hashingTF, idf, clean_up])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0MKKhBb7WxZ"
      },
      "source": [
        "# Fit and transform the pipeline\r\n",
        "cleaner = data_prep_pipeline.fit(df_git_clean)\r\n",
        "cleaned = cleaner.transform(df_git_clean)\r\n",
        "#cleaned.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDODyxF7NYCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bbc264-870c-4a36-fa4c-a5c707df86c0"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned_final = cleaned.select(['label', 'features'])\n",
        "cleaned_final.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    2|(8192,[309,1322,2...|\n",
            "|    0|(8192,[145,191,38...|\n",
            "|    0|(8192,[1506,4808,...|\n",
            "|    0|(8192,[110,655,69...|\n",
            "|    2|(8192,[33,1002,17...|\n",
            "|    2|(8192,[1805,2844,...|\n",
            "|    1|(8192,[1446,1621,...|\n",
            "|    2|(8192,[159,497,13...|\n",
            "|    2|(8192,[1575,1836,...|\n",
            "|    0|(8192,[265,322,14...|\n",
            "|    1|(8192,[191,537,20...|\n",
            "|    1|(8192,[697,1598,5...|\n",
            "|    0|(8192,[1941,5372,...|\n",
            "|    0|(8192,[368,1002,1...|\n",
            "|    2|(8192,[1065,3756,...|\n",
            "|    0|(8192,[110,966,15...|\n",
            "|    2|(8192,[110,345,92...|\n",
            "|    0|(8192,[191,4541,4...|\n",
            "|    0|(8192,[309,2566,4...|\n",
            "|    1|(8192,[111,223,54...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzfCQmrVNYCr"
      },
      "source": [
        "# Break data down into a training set and a testing set (train with 70%, test with 30%)\n",
        "#training, testing = cleaned_final.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Perform a stratified split to preserve class distribution\n",
        "# Source: https://stackoverflow.com/questions/47637760/stratified-sampling-with-pyspark\n",
        "\n",
        "# split dataframes between 0s, 1s, and 2s\n",
        "zeros = cleaned_final.filter(cleaned_final[\"label\"]==0)\n",
        "ones = cleaned_final.filter(cleaned_final[\"label\"]==1)\n",
        "twos = cleaned_final.filter(cleaned_final[\"label\"]==2)\n",
        "\n",
        "# split datasets into training and testing\n",
        "\n",
        "train0, test0 = zeros.randomSplit([0.8,0.2], seed=1234)\n",
        "train1, test1 = ones.randomSplit([0.8,0.2], seed=1234)\n",
        "train2, test2 = twos.randomSplit([0.8,0.2], seed=1234)\n",
        "# stack datasets back together\n",
        "training = train0.union(train1).union(train2)\n",
        "testing = test0.union(test1).union(test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZtb-UmKQ6cF"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\r\n",
        "# Create a Naive Bayes model and fit training data\r\n",
        "nb = NaiveBayes()\r\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeckHhg5NYCv"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "#test_results.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVFrWcHINYCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47444dc-1504-491c-8d4c-7878f9f89836"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting sentiment was: %f\" % acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting sentiment was: 0.634867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpKc638NlCQ"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression, OneVsRest\r\n",
        "\r\n",
        "# instantiate the base classifier.\r\n",
        "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\r\n",
        "\r\n",
        "# instantiate the One Vs Rest Classifier.\r\n",
        "ovr = OneVsRest(classifier=lr)\r\n",
        "\r\n",
        "# train the multiclass model.\r\n",
        "ovrModel = ovr.fit(training)\r\n",
        "\r\n",
        "# score the model on test data.\r\n",
        "predictions = ovrModel.transform(testing)\r\n",
        "#predictions.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKSiDZ16Jv0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df0cf02-efb4-4fe3-e637-dccbebd3a878"
      },
      "source": [
        "# obtain evaluator.\r\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\r\n",
        "\r\n",
        "# compute the classification error on test data.\r\n",
        "accuracy = evaluator.evaluate(predictions)\r\n",
        "print(\"Accuracy of model at predicting sentiment was: %f\" % accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting sentiment was: 0.639405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5omszR9CawG"
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\r\n",
        "\r\n",
        "# specify layers for the neural network:\r\n",
        "# input layer of size 4 (features), two intermediate of size 5 and 4\r\n",
        "# and output of size 3 (classes)\r\n",
        "layers = [cleaned_final.schema['features'].metadata['ml_attr']['num_attrs'], 5, 4, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shEWjnaSKfHB"
      },
      "source": [
        "# create the trainer and set its parameters\r\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\r\n",
        "\r\n",
        "# train the model\r\n",
        "model = trainer.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuEIdyeuKihq",
        "outputId": "a40f1d8a-7c50-451d-a5be-7695b42880f8"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "# compute accuracy on the test set\r\n",
        "result = model.transform(testing)\r\n",
        "predictionAndLabels = result.select(\"prediction\", \"label\")\r\n",
        "\r\n",
        "# obtain evaluator.\r\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\r\n",
        "\r\n",
        "print(\"Accuracy of model at predicting sentiment was: \" + str(evaluator.evaluate(result)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting sentiment was: 0.6282527881040892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WWKivVAKuVK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}